{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkYPbKxrPbww",
        "outputId": "77e603ac-29f9-4efb-962d-434ec6719798"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dq-YbSh2U5k"
      },
      "source": [
        "##import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "kP8WrLr7m8tU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import os\n",
        "from keras.preprocessing import image\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5U9y2qE2RYo"
      },
      "source": [
        "##load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "yEm8FxcYnvJ3"
      },
      "outputs": [],
      "source": [
        "from logging import info\n",
        "setattr(tfds.image_classification.cats_vs_dogs, '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")\n",
        "train ,validation ,test = tfds.load('cats_vs_dogs',split=['train[:70%]','train[70%:80%]','train[80%:]'], shuffle_files=True, as_supervised=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDtTFixVQaQo"
      },
      "source": [
        "##data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "K7wddOk-S1jo"
      },
      "outputs": [],
      "source": [
        "def normalization(img, label):\n",
        "    temp = (tf.image.resize(img, (output_dim, output_dim))) / 255\n",
        "    return temp\n",
        "output_dim = 56\n",
        "train = train.map(normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ZvzM6u_6YYE8"
      },
      "outputs": [],
      "source": [
        "list_train = list(train.as_numpy_iterator())\n",
        "train = np.array(list_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZmZ4XRJNouR",
        "outputId": "5caf2352-f1a1-4e53-e7b3-d616dcf89afb"
      },
      "outputs": [],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gB3TxuyCk08S",
        "outputId": "99400479-c294-4e27-a65d-f7ea4fd12185"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1) \n",
        "  plt.imshow(train[i])\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkxRMfdwf-DH",
        "outputId": "fa1e23d2-bda0-4862-d51c-400f0b8f0e15"
      },
      "outputs": [],
      "source": [
        "print(np.max(train[:,:,:]), np.min(train[:,:,:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5LaAN9N2I62"
      },
      "source": [
        "##DCGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le7OYcKbu2uq"
      },
      "source": [
        "make generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "7NFBjpqg9uk8",
        "outputId": "3ba9f8cf-eb86-4e6b-9b41-7cc121ec899b"
      },
      "outputs": [],
      "source": [
        "latent_dim = 56\n",
        "height = 56\n",
        "width = 56\n",
        "channels = 3\n",
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(128 * 28 * 28)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((28, 28, 128))(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()\n",
        "'''latent_dim = 56\n",
        "height = 56\n",
        "width = 56\n",
        "channels = 3\n",
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(64 * 14 * 14)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((14, 14, 64))(x)\n",
        "x = layers.Conv2D(64, 5,strides=1, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(128, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSucpDsVu88a"
      },
      "source": [
        "make discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XgbLhYh-Pzd",
        "outputId": "7e81c15a-7086-4312-8829-4923b31f894a"
      },
      "outputs": [],
      "source": [
        "discriminator_input = layers.Input(shape=(height, width, channels))\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "discriminator = keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()\n",
        "discriminator_optimizer = keras.optimizers.RMSprop( lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmCpt5sx51ou",
        "outputId": "561e0a22-c95c-4306-9acc-da1b41ae3176"
      },
      "outputs": [],
      "source": [
        "discriminator.trainable = False\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n",
        "gan.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "YwXmn7seuB1L"
      },
      "outputs": [],
      "source": [
        "iterations = 3000\n",
        "batch_size = 20\n",
        "save_dir = '/content/drive/MyDrive/logs/gan'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS6B5_Bzg0a5",
        "outputId": "51046534-0dfe-437f-c1ec-d7cd75da72dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((20, 56, 56, 3), (20, 56, 56, 3))"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "real_images = train[0: 20]\n",
        "random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "random_latent_vectors.shape\n",
        "generated_images = generator.predict(random_latent_vectors)\n",
        "generated_images.shape  , real_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCz4TNKl0g2n",
        "outputId": "b7f5a02e-3f4f-4cbf-a176-4cd296e7d248"
      },
      "outputs": [],
      "source": [
        "start = 0\n",
        "noise_strenght = 0.1\n",
        "for step in range(iterations):\n",
        "  #تولید بیست بردار رندوم با بعد 56\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "  #تولید بیست تصویر با استفاده از مولد\n",
        "  generated_images = generator.predict(random_latent_vectors)\n",
        "\n",
        "  stop = start + batch_size\n",
        "  #بیست تصویر واقعی \n",
        "  real_images = train[start: stop]\n",
        "  real_images += noise_strenght * np.random.random(real_images.shape)\n",
        "  #ترکیب تصاویر واقعی و مجازی\n",
        "  combined_images = np.concatenate([generated_images, real_images])\n",
        "  #اختصاص برچسب یک به مجازی و صفر به واقعی    \n",
        "  labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
        "  #یه تریک برای اموزش\n",
        "  labels += 0.05 * np.random.random(labels.shape)\n",
        "  #اموزش متمایزگز\n",
        "  d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "  #تولید بیست نمونه مجازی\n",
        "  random_latent_vectors = np.random.normal(size=( batch_size, latent_dim))\n",
        "  #به بیست نمونه مجازی برچسب واقعی میدهیم\n",
        "  misleading_targets = np.zeros((batch_size, 1))\n",
        "  #اموزش مولد\n",
        "  a_loss = gan.train_on_batch( random_latent_vectors, misleading_targets)\n",
        "  start += batch_size\n",
        "  if start > len(train) - batch_size:\n",
        "    start = 0\n",
        "  if step % 100 == 0:\n",
        "    gan.save_weights('gan.h5')\n",
        "    print('discriminator loss:', d_loss)\n",
        "    print('adversarial loss:', a_loss)\n",
        "    img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_dir , 'generated' + str(step) + '.png'))\n",
        "    img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_dir, 'real' + str(step) + '.png'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z_FYMRmBTvD"
      },
      "source": [
        "genearte 100 sample from dcgan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-ELpnyAtA4eU",
        "outputId": "c563f754-13b3-4d8c-bca0-20983f95db13"
      },
      "outputs": [],
      "source": [
        "noise = np.random.normal(size=(100, latent_dim))\n",
        "show_images(noise,(10,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "oJ-vXAymIMsA"
      },
      "outputs": [],
      "source": [
        "def show_images(noise, size_fig):\n",
        "    generated_images = generator.predict(noise)   #Create the images from the GAN.\n",
        "    plt.figure(figsize=size_fig)\n",
        "    \n",
        "    for i, image in enumerate(generated_images):\n",
        "        plt.subplot(size_fig[0], size_fig[1], i+1)\n",
        "        plt.imshow(image.reshape((56, 56, 3)))\n",
        "        plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()   #Tight layout so that all of the generated images form a nice grid\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sic2R6z_oFi"
      },
      "source": [
        "##FCGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoUPrEIB0g0A"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(0.0002, 0.5)\n",
        "def create_generator():\n",
        "    generator = Sequential()\n",
        "\n",
        "    generator.add(Dense(128, input_dim=56))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(256))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "    \n",
        "    generator.add(Dense(512))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "    \n",
        "    generator.add(Dense(1024))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(2048, input_dim=56))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "    \n",
        "    generator.add(Dense(56*56*3, activation='tanh'))\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    return generator  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6NBsBck0gv1",
        "outputId": "c6b2fd07-a8f5-4940-945e-5577bd8478c8"
      },
      "outputs": [],
      "source": [
        "fc_generated = create_generator()\n",
        "fc_generated.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXEJO0y8yVXb"
      },
      "outputs": [],
      "source": [
        "def create_discriminator():\n",
        "    discriminator = Sequential()\n",
        "    \n",
        "    discriminator.add(Dense(1024, input_dim=56*56*3))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    \n",
        "    discriminator.add(Dense(512))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    \n",
        "    discriminator.add(Dense(256))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    \n",
        "    discriminator.add(Dense(1, activation='sigmoid'))\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer = optimizer)\n",
        "    return discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL4atyEiyV4d",
        "outputId": "8dcf632f-e08e-44d7-ea8e-94d6c0561ec3"
      },
      "outputs": [],
      "source": [
        "fc_discriminator = create_discriminator()\n",
        "fc_discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e7vsLW64t1W",
        "outputId": "4b9eec93-da38-435d-9892-9625b4055d25"
      },
      "outputs": [],
      "source": [
        "fc_discriminator.trainable = False \n",
        "fc_gan_input = keras.layers.Input(shape=(56,))\n",
        "fc_fake_image = fc_generated(fc_gan_input)\n",
        "fc_gan_output = fc_discriminator(fc_fake_image)\n",
        "fc_gan =keras.models.Model(fc_gan_input, fc_gan_output)\n",
        "fc_gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "fc_gan.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA3-MVch-v-P"
      },
      "source": [
        "train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2LN45rFDmAS",
        "outputId": "09b6d9bc-74bc-4411-c1a8-ac15fad878eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16000, 56, 56, 3)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_x = train[:16000]\n",
        "train_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNBu6l9yKvAw",
        "outputId": "a640c655-3cae-460a-dc4f-0b3a4e9c428b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "latent_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaQRrCp-jHdN",
        "outputId": "07c59e7e-d292-46d5-deed-88de60fc8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((20, 9408), (20, 9408))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "latent_dim = 56\n",
        "batch_size = 20\n",
        "random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "generated_images = fc_generated.predict(random_latent_vectors)\n",
        "real_images = train[0: 20]\n",
        "new = np.reshape(real_images,(20, 9408))\n",
        "generated_images.shape , new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mumq5N-TlhQm",
        "outputId": "75e4aedf-6549-4ad8-b3b9-82b5cedfaf3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(real_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1ts8fsUnrOK",
        "outputId": "b45d5247-6cec-4591-9723-993546b0c1ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 9408)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3eBx4FaIRTI",
        "outputId": "da09c624-4209-4fdf-e137-a84ed1068888"
      },
      "outputs": [],
      "source": [
        "start = 0\n",
        "iterations = 1000\n",
        "batch_size = 20 \n",
        "save_directory = '/content/drive/MyDrive/logs/fc_gan'\n",
        "discriminator_loss = []\n",
        "genarator_loss = []\n",
        "noise_strenght = 0.003\n",
        "for step in range(iterations):\n",
        "  #تولید بیست بردار رندوم با بعد 56\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "  #تولید بیست تصویر با استفاده از مولد\n",
        "  generated_images = fc_generated.predict(random_latent_vectors)\n",
        "\n",
        "  stop = start + batch_size\n",
        "  #بیست تصویر واقعی \n",
        "  real_images = train[start: stop]\n",
        "  #اضافه کردن نویز به تصاویر ورودی برای متعادل سازی\n",
        "  real_images += noise_strenght * np.random.random(real_images.shape)\n",
        "  new_real_images = np.reshape(real_images,(20, 9408))\n",
        "  #ترکیب تصاویر واقعی و مجازی\n",
        "  combined_images = np.concatenate([generated_images, new_real_images])\n",
        "  #اختصاص برچسب یک به مجازی و صفر به واقعی    \n",
        "  labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
        "  #یه تریک برای اموزش\n",
        "  labels += 0.05 * np.random.random(labels.shape)\n",
        "  #اموزش متمایزگز\n",
        "  d_loss = fc_discriminator.train_on_batch(combined_images, labels)\n",
        "  #تولید بیست نمونه مجازی\n",
        "  random_latent_vectors = np.random.normal(size=( batch_size, latent_dim))\n",
        "  #به بیست نمونه مجازی برچسب واقعی میدهیم\n",
        "  misleading_targets = np.zeros((batch_size, 1))\n",
        "  #اموزش مولد\n",
        "  a_loss = fc_gan.train_on_batch( random_latent_vectors, misleading_targets)\n",
        "  start += batch_size\n",
        "  discriminator_loss.append(d_loss)\n",
        "  genarator_loss.append(a_loss)\n",
        "\n",
        "  if start > len(train) - batch_size:\n",
        "    start = 0\n",
        "  if step % 100 == 0:\n",
        "    fc_gan.save_weights('gan.h5')\n",
        "    print('discriminator loss:', d_loss)\n",
        "    print('generator loss:', a_loss)\n",
        "\n",
        "    generated_images = np.reshape(generated_images,(20,56,56,3))\n",
        "\n",
        "    img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_directory , 'fc_gan_generated' + str(step) + '.png'))\n",
        "    img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_directory, 'fc_real' + str(step) + '.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "6wxJ09a6Iepe",
        "outputId": "37477484-722c-44a4-b7a8-3c725104bd7f"
      },
      "outputs": [],
      "source": [
        "plt.plot(discriminator_loss, label='discriminator')\n",
        "plt.plot(genarator_loss, label='genarator')\n",
        "plt.title('LOSS')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_dq-YbSh2U5k",
        "E5U9y2qE2RYo",
        "lDtTFixVQaQo",
        "p5LaAN9N2I62",
        "9sic2R6z_oFi"
      ],
      "name": "tamrin 7 .ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
